{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "from q2_initialization import *\n",
    "from q2_NER import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running basic tests...\n",
      "Basic (non-exhaustive) Xavier initialization tests pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_initialization_basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running your tests...\n",
      "Expected Xavier initializer:  0.454858826147\n",
      "Actual Xavier initializer:  0.45374\n"
     ]
    }
   ],
   "source": [
    "test_initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training loss: 1.04356265068265068\n",
      "Training acc: 0.810196394282\n",
      "Validation loss: 0.992531657219\n",
      "\n",
      "[[42562    26    39    38    94]\n",
      " [  317  1481    37   165    94]\n",
      " [  449    38   726    25    30]\n",
      " [  862    97    46   968   119]\n",
      " [  727    21     1    43  2357]]\n",
      "Tag: O - P 0.9476 / R 0.9954\n",
      "Tag: LOC - P 0.8906 / R 0.7073\n",
      "Tag: MISC - P 0.8551 / R 0.5726\n",
      "Tag: ORG - P 0.7813 / R 0.4627\n",
      "Tag: PER - P 0.8749 / R 0.7485\n",
      "Total time: 94.8493640423\n",
      "Epoch 1\n",
      "Training loss: 0.985366165638165638\n",
      "Training acc: 0.861777518036\n",
      "Validation loss: 0.980269372463\n",
      "\n",
      "[[42452    44    37    94   132]\n",
      " [  242  1647    12   119    74]\n",
      " [  321    37   859    22    29]\n",
      " [  690   120    28  1132   122]\n",
      " [  556    26     3    27  2537]]\n",
      "Tag: O - P 0.9591 / R 0.9928\n",
      "Tag: LOC - P 0.8789 / R 0.7865\n",
      "Tag: MISC - P 0.9148 / R 0.6774\n",
      "Tag: ORG - P 0.8121 / R 0.5411\n",
      "Tag: PER - P 0.8766 / R 0.8057\n",
      "Total time: 105.173842907\n",
      "Epoch 2\n",
      "Training loss: 0.972455978394978394\n",
      "Training acc: 0.870769714322\n",
      "Validation loss: 0.975308060646\n",
      "\n",
      "[[42407    48    40   138   126]\n",
      " [  216  1697    30    91    60]\n",
      " [  325    27   873    20    23]\n",
      " [  620   128    32  1200   112]\n",
      " [  499    27     3    48  2572]]\n",
      "Tag: O - P 0.9623 / R 0.9918\n",
      "Tag: LOC - P 0.8806 / R 0.8104\n",
      "Tag: MISC - P 0.8926 / R 0.6885\n",
      "Tag: ORG - P 0.8016 / R 0.5736\n",
      "Tag: PER - P 0.8890 / R 0.8168\n",
      "Total time: 101.862946033\n",
      "Epoch 3\n",
      "Training loss: 0.966261923313923313\n",
      "Training acc: 0.874654382407\n",
      "Validation loss: 0.972771644592\n",
      "\n",
      "[[42353    50    53   152   151]\n",
      " [  168  1683    20   147    76]\n",
      " [  298    29   884    28    29]\n",
      " [  576    88    29  1281   118]\n",
      " [  409    27     5    56  2652]]\n",
      "Tag: O - P 0.9669 / R 0.9905\n",
      "Tag: LOC - P 0.8966 / R 0.8037\n",
      "Tag: MISC - P 0.8920 / R 0.6972\n",
      "Tag: ORG - P 0.7698 / R 0.6123\n",
      "Tag: PER - P 0.8764 / R 0.8422\n",
      "Total time: 105.679527044\n",
      "Epoch 4\n",
      "Training loss: 0.960600137711137711\n",
      "Training acc: 0.879614578064\n",
      "Validation loss: 0.971205413342\n",
      "\n",
      "[[42370    42    47   193   107]\n",
      " [  179  1749    19    92    55]\n",
      " [  312    32   875    31    18]\n",
      " [  568   123    27  1290    84]\n",
      " [  463    26     4    94  2562]]\n",
      "Tag: O - P 0.9653 / R 0.9909\n",
      "Tag: LOC - P 0.8869 / R 0.8352\n",
      "Tag: MISC - P 0.9002 / R 0.6901\n",
      "Tag: ORG - P 0.7588 / R 0.6166\n",
      "Tag: PER - P 0.9066 / R 0.8136\n",
      "Total time: 110.589051962\n",
      "Epoch 5\n",
      "Training loss: 0.959028422832422832\n",
      "Training acc: 0.88024319692\n",
      "Validation loss: 0.969738721848\n",
      "\n",
      "[[42274    60    47   238   140]\n",
      " [  155  1771    20    92    56]\n",
      " [  304    30   879    30    25]\n",
      " [  514   109    36  1323   110]\n",
      " [  344    23     3   105  2674]]\n",
      "Tag: O - P 0.9698 / R 0.9887\n",
      "Tag: LOC - P 0.8886 / R 0.8457\n",
      "Tag: MISC - P 0.8924 / R 0.6932\n",
      "Tag: ORG - P 0.7399 / R 0.6324\n",
      "Tag: PER - P 0.8899 / R 0.8492\n",
      "Total time: 94.082886219\n",
      "Epoch 6\n",
      "Training loss: 0.957058310509310509\n",
      "Training acc: 0.882404074236\n",
      "Validation loss: 0.968327999115\n",
      "\n",
      "[[42310    57    53   226   113]\n",
      " [  168  1773    18    92    43]\n",
      " [  296    32   882    37    21]\n",
      " [  531    84    28  1358    91]\n",
      " [  434    36     4    93  2582]]\n",
      "Tag: O - P 0.9673 / R 0.9895\n",
      "Tag: LOC - P 0.8946 / R 0.8467\n",
      "Tag: MISC - P 0.8954 / R 0.6956\n",
      "Tag: ORG - P 0.7519 / R 0.6491\n",
      "Tag: PER - P 0.9060 / R 0.8199\n",
      "Total time: 104.826699972\n",
      "Epoch 7\n",
      "Training loss: 0.955431342125342125\n",
      "Training acc: 0.884451996602\n",
      "Validation loss: 0.968266308308\n",
      "\n",
      "[[42168    69    87   253   182]\n",
      " [  138  1793    25    75    63]\n",
      " [  290    27   893    34    24]\n",
      " [  457   103    44  1361   127]\n",
      " [  366    23    14    62  2684]]\n",
      "Tag: O - P 0.9712 / R 0.9862\n",
      "Tag: LOC - P 0.8898 / R 0.8563\n",
      "Tag: MISC - P 0.8401 / R 0.7043\n",
      "Tag: ORG - P 0.7625 / R 0.6506\n",
      "Tag: PER - P 0.8714 / R 0.8523\n",
      "Total time: 99.4696409702\n",
      "Epoch 8\n",
      "Training loss: 0.953411698341698341\n",
      "Training acc: 0.886892805752\n",
      "Validation loss: 0.965534210205\n",
      "\n",
      "[[42407    44    45   148   115]\n",
      " [  177  1773    27    64    53]\n",
      " [  340    23   856    27    22]\n",
      " [  591    94    33  1285    89]\n",
      " [  443    23     4    56  2623]]\n",
      "Tag: O - P 0.9647 / R 0.9918\n",
      "Tag: LOC - P 0.9060 / R 0.8467\n",
      "Tag: MISC - P 0.8870 / R 0.6751\n",
      "Tag: ORG - P 0.8133 / R 0.6142\n",
      "Tag: PER - P 0.9039 / R 0.8330\n",
      "Total time: 93.2719709873\n",
      "Epoch 9\n",
      "Training loss: 0.952841758728758728\n",
      "Training acc: 0.888464352891\n",
      "Validation loss: 0.964594125748\n",
      "\n",
      "[[42343    44    47   165   160]\n",
      " [  163  1733    21    96    81]\n",
      " [  319    25   865    32    27]\n",
      " [  522    76    29  1346   119]\n",
      " [  405    19     1    55  2669]]\n",
      "Tag: O - P 0.9678 / R 0.9903\n",
      "Tag: LOC - P 0.9135 / R 0.8276\n",
      "Tag: MISC - P 0.8982 / R 0.6822\n",
      "Tag: ORG - P 0.7946 / R 0.6434\n",
      "Tag: PER - P 0.8734 / R 0.8476\n",
      "Total time: 107.394038916\n",
      "Epoch 10\n",
      "Training loss: 0.951305747032747032\n",
      "Training acc: 0.89093462855\n",
      "Validation loss: 0.963929772377\n",
      "\n",
      "[[42337    68    46   176   132]\n",
      " [  159  1797    17    74    47]\n",
      " [  316    36   868    29    19]\n",
      " [  514   105    29  1336   108]\n",
      " [  410    35     5    50  2649]]\n",
      "Tag: O - P 0.9680 / R 0.9901\n",
      "Tag: LOC - P 0.8805 / R 0.8582\n",
      "Tag: MISC - P 0.8995 / R 0.6845\n",
      "Tag: ORG - P 0.8024 / R 0.6386\n",
      "Tag: PER - P 0.8964 / R 0.8412\n",
      "Total time: 93.9940888882\n",
      "Epoch 11\n",
      "Training loss: 0.950091958046958046\n",
      "Training acc: 0.893512948075\n",
      "Validation loss: 0.965038478374\n",
      "\n",
      "[[42222    51    81   244   161]\n",
      " [  150  1762    26    88    68]\n",
      " [  296    22   895    31    24]\n",
      " [  484    72    28  1395   113]\n",
      " [  418    20     6    52  2653]]\n",
      "Tag: O - P 0.9691 / R 0.9874\n",
      "Tag: LOC - P 0.9144 / R 0.8415\n",
      "Tag: MISC - P 0.8639 / R 0.7058\n",
      "Tag: ORG - P 0.7707 / R 0.6668\n",
      "Tag: PER - P 0.8788 / R 0.8425\n",
      "Total time: 87.8202719688\n",
      "Epoch 12\n",
      "Training loss: 0.949949800968800968\n",
      "Training acc: 0.894338010323\n",
      "Validation loss: 0.963245868683\n",
      "\n",
      "[[42283    51    40   232   153]\n",
      " [  171  1770    15    86    52]\n",
      " [  319    26   865    36    22]\n",
      " [  495    76    24  1388   109]\n",
      " [  416    28     1    50  2654]]\n",
      "Tag: O - P 0.9679 / R 0.9889\n",
      "Tag: LOC - P 0.9072 / R 0.8453\n",
      "Tag: MISC - P 0.9153 / R 0.6822\n",
      "Tag: ORG - P 0.7746 / R 0.6635\n",
      "Tag: PER - P 0.8876 / R 0.8428\n",
      "Total time: 90.3216030598\n",
      "Epoch 13\n",
      "Training loss: 0.948729693899693897\n",
      "Training acc: 0.896547998487\n",
      "Validation loss: 0.963256299496\n",
      "\n",
      "[[42245    49    69   265   131]\n",
      " [  162  1760    24    83    65]\n",
      " [  301    26   891    28    22]\n",
      " [  501    85    33  1360   113]\n",
      " [  434    17     3    43  2652]]\n",
      "Tag: O - P 0.9680 / R 0.9880\n",
      "Tag: LOC - P 0.9086 / R 0.8405\n",
      "Tag: MISC - P 0.8735 / R 0.7027\n",
      "Tag: ORG - P 0.7645 / R 0.6501\n",
      "Tag: PER - P 0.8890 / R 0.8422\n",
      "Total time: 94.085504055\n",
      "Epoch 14\n",
      "Training loss: 0.948208630085630085\n",
      "Training acc: 0.898694142549\n",
      "Validation loss: 0.963307857513\n",
      "\n",
      "[[42244    56    57   271   131]\n",
      " [  153  1795    15    85    46]\n",
      " [  310    32   872    39    15]\n",
      " [  493   103    27  1376    93]\n",
      " [  394    34     5    84  2632]]\n",
      "Tag: O - P 0.9690 / R 0.9880\n",
      "Tag: LOC - P 0.8886 / R 0.8572\n",
      "Tag: MISC - P 0.8934 / R 0.6877\n",
      "Tag: ORG - P 0.7418 / R 0.6577\n",
      "Tag: PER - P 0.9023 / R 0.8358\n",
      "Total time: 89.3505628109\n",
      "Epoch 15\n",
      "Training loss: 0.947574377064377067\n",
      "Training acc: 0.900967974816\n",
      "Validation loss: 0.961874067783\n",
      "\n",
      "[[42292    65    77   183   142]\n",
      " [  160  1802    16    62    54]\n",
      " [  300    29   890    26    23]\n",
      " [  511   101    33  1339   108]\n",
      " [  402    30     6    50  2661]]\n",
      "Tag: O - P 0.9686 / R 0.9891\n",
      "Tag: LOC - P 0.8890 / R 0.8606\n",
      "Tag: MISC - P 0.8708 / R 0.7019\n",
      "Tag: ORG - P 0.8066 / R 0.6401\n",
      "Tag: PER - P 0.8906 / R 0.8450\n",
      "Total time: 95.0232591629\n",
      "Epoch 16\n",
      "Training loss: 0.947341918945918945\n",
      "Training acc: 0.901419794618\n",
      "Validation loss: 0.962716817856\n",
      "\n",
      "[[42244    56    85   246   128]\n",
      " [  160  1807    18    55    54]\n",
      " [  297    33   892    28    18]\n",
      " [  500   126    37  1332    97]\n",
      " [  425    33     8    61  2622]]\n",
      "Tag: O - P 0.9683 / R 0.9880\n",
      "Tag: LOC - P 0.8793 / R 0.8629\n",
      "Tag: MISC - P 0.8577 / R 0.7035\n",
      "Tag: ORG - P 0.7735 / R 0.6367\n",
      "Tag: PER - P 0.8983 / R 0.8326\n",
      "Total time: 104.85159421\n",
      "Epoch 17\n",
      "Training loss: 0.947028875351875351\n",
      "Training acc: 0.90280963162\n",
      "Validation loss: 0.963408410549\n",
      "\n",
      "[[42240   101    62   259    97]\n",
      " [  158  1777    26    99    34]\n",
      " [  311    28   878    36    15]\n",
      " [  493   101    32  1386    80]\n",
      " [  432    69     6    64  2578]]\n",
      "Tag: O - P 0.9681 / R 0.9879\n",
      "Tag: LOC - P 0.8560 / R 0.8486\n",
      "Tag: MISC - P 0.8745 / R 0.6924\n",
      "Tag: ORG - P 0.7516 / R 0.6625\n",
      "Tag: PER - P 0.9194 / R 0.8187\n",
      "Total time: 89.423074007\n",
      "Epoch 18\n",
      "Training loss: 0.945848643788643783\n",
      "Training acc: 0.904926309172\n",
      "Validation loss: 0.962287425995\n",
      "Test\n",
      "=-=-=\n",
      "Writing predictions to q2_test.predicted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/prabhakar/tensorflow/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "test_NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training loss: 1.04275894165894165\n",
      "Training acc: 0.809621797359\n",
      "Validation loss: 0.997374296188\n",
      "\n",
      "[[42472    30     0   116   141]\n",
      " [  269  1512     0   210   103]\n",
      " [  589   131     0   392   156]\n",
      " [  718    80     0  1149   145]\n",
      " [  568    23     0    56  2502]]\n",
      "Tag: O - P 0.9519 / R 0.9933\n",
      "Tag: LOC - P 0.8514 / R 0.7221\n",
      "Tag: MISC - P nan / R 0.0000\n",
      "Tag: ORG - P 0.5975 / R 0.5492\n",
      "Tag: PER - P 0.8211 / R 0.7945\n",
      "Total time: 101.427340984\n",
      "Epoch 1\n",
      "Training loss: 0.986922442913442913\n",
      "Training acc: 0.860535013579\n",
      "Validation loss: 0.980961978436\n",
      "\n",
      "[[42396    27    40   119   177]\n",
      " [  193  1633    39   120   109]\n",
      " [  410    24   773    28    33]\n",
      " [  648   107    29  1190   118]\n",
      " [  442    22     3    32  2650]]\n",
      "Tag: O - P 0.9616 / R 0.9915\n",
      "Tag: LOC - P 0.9007 / R 0.7798\n",
      "Tag: MISC - P 0.8744 / R 0.6096\n",
      "Tag: ORG - P 0.7992 / R 0.5688\n",
      "Tag: PER - P 0.8584 / R 0.8415\n",
      "Total time: 99.8500649929\n",
      "Epoch 2\n",
      "Training loss: 0.972378671169671169\n",
      "Training acc: 0.871624243079\n",
      "Validation loss: 0.975517690182\n",
      "\n",
      "[[42353    33    74   137   162]\n",
      " [  172  1685    35   122    80]\n",
      " [  324    23   867    25    29]\n",
      " [  584    94    35  1254   125]\n",
      " [  375    23     5    76  2670]]\n",
      "Tag: O - P 0.9668 / R 0.9905\n",
      "Tag: LOC - P 0.9069 / R 0.8047\n",
      "Tag: MISC - P 0.8533 / R 0.6838\n",
      "Tag: ORG - P 0.7770 / R 0.5994\n",
      "Tag: PER - P 0.8708 / R 0.8479\n",
      "Total time: 99.6767389774\n",
      "Epoch 3\n",
      "Training loss: 0.965606570244570244\n",
      "Training acc: 0.875941086627\n",
      "Validation loss: 0.973614513874\n",
      "\n",
      "[[42264    42    71   148   234]\n",
      " [  167  1758    20    65    84]\n",
      " [  300    34   870    27    37]\n",
      " [  550   144    32  1235   131]\n",
      " [  356    25     5    44  2719]]\n",
      "Tag: O - P 0.9685 / R 0.9884\n",
      "Tag: LOC - P 0.8777 / R 0.8395\n",
      "Tag: MISC - P 0.8717 / R 0.6861\n",
      "Tag: ORG - P 0.8130 / R 0.5903\n",
      "Tag: PER - P 0.8484 / R 0.8634\n",
      "Total time: 105.773401022\n",
      "Epoch 4\n",
      "Training loss: 0.961563110352110352\n",
      "Training acc: 0.878450650964\n",
      "Validation loss: 0.970572710037\n",
      "\n",
      "[[42370    30    58   183   118]\n",
      " [  169  1716    36   122    51]\n",
      " [  315    25   873    30    25]\n",
      " [  561    83    31  1328    89]\n",
      " [  422    21     9    79  2618]]\n",
      "Tag: O - P 0.9665 / R 0.9909\n",
      "Tag: LOC - P 0.9152 / R 0.8195\n",
      "Tag: MISC - P 0.8669 / R 0.6885\n",
      "Tag: ORG - P 0.7623 / R 0.6348\n",
      "Tag: PER - P 0.9024 / R 0.8314\n",
      "Total time: 105.410625935\n",
      "Epoch 5\n",
      "Training loss: 0.959833443165443165\n",
      "Training acc: 0.879167669346\n",
      "Validation loss: 0.970462560654\n",
      "\n",
      "[[42263    31    80   205   180]\n",
      " [  151  1688    51   134    70]\n",
      " [  301    23   882    31    31]\n",
      " [  529    71    37  1346   109]\n",
      " [  365    22    10    69  2683]]\n",
      "Tag: O - P 0.9691 / R 0.9884\n",
      "Tag: LOC - P 0.9199 / R 0.8061\n",
      "Tag: MISC - P 0.8321 / R 0.6956\n",
      "Tag: ORG - P 0.7541 / R 0.6434\n",
      "Tag: PER - P 0.8731 / R 0.8520\n",
      "Total time: 101.608714104\n",
      "Epoch 6\n",
      "Training loss: 0.956989526749526749\n",
      "Training acc: 0.882065209384\n",
      "Validation loss: 0.969219446182\n",
      "\n",
      "[[42363    44    63   194    95]\n",
      " [  174  1716    35   120    49]\n",
      " [  313    26   870    37    22]\n",
      " [  559    68    27  1364    74]\n",
      " [  544    20     4    65  2516]]\n",
      "Tag: O - P 0.9638 / R 0.9907\n",
      "Tag: LOC - P 0.9157 / R 0.8195\n",
      "Tag: MISC - P 0.8709 / R 0.6861\n",
      "Tag: ORG - P 0.7663 / R 0.6520\n",
      "Tag: PER - P 0.9129 / R 0.7990\n",
      "Total time: 106.274750948\n",
      "Epoch 7\n",
      "Training loss: 0.955120027065027065\n",
      "Training acc: 0.88448146311\n",
      "Validation loss: 0.966882109642\n",
      "\n",
      "[[42316    55    89   148   151]\n",
      " [  149  1785    32    59    69]\n",
      " [  304    24   890    25    25]\n",
      " [  565   113    36  1279    99]\n",
      " [  426    20    11    49  2643]]\n",
      "Tag: O - P 0.9670 / R 0.9896\n",
      "Tag: LOC - P 0.8938 / R 0.8524\n",
      "Tag: MISC - P 0.8412 / R 0.7019\n",
      "Tag: ORG - P 0.8199 / R 0.6114\n",
      "Tag: PER - P 0.8848 / R 0.8393\n",
      "Total time: 107.484963894\n",
      "Epoch 8\n",
      "Training loss: 0.953707218177218172\n",
      "Training acc: 0.887570535456\n",
      "Validation loss: 0.966649591923\n",
      "\n",
      "[[42422    41    66   140    90]\n",
      " [  177  1765    23    79    50]\n",
      " [  319    25   878    28    18]\n",
      " [  586    92    38  1305    71]\n",
      " [  567    22     8    44  2508]]\n",
      "Tag: O - P 0.9626 / R 0.9921\n",
      "Tag: LOC - P 0.9075 / R 0.8429\n",
      "Tag: MISC - P 0.8667 / R 0.6924\n",
      "Tag: ORG - P 0.8177 / R 0.6238\n",
      "Tag: PER - P 0.9163 / R 0.7964\n",
      "Total time: 100.001534939\n",
      "Epoch 9\n",
      "Training loss: 0.952967464924464924\n",
      "Training acc: 0.8881058437\n",
      "Validation loss: 0.965262889862\n",
      "\n",
      "[[42316    34    46   197   166]\n",
      " [  159  1750    18   102    65]\n",
      " [  321    27   865    33    22]\n",
      " [  551    77    25  1335   104]\n",
      " [  432    19     3    62  2633]]\n",
      "Tag: O - P 0.9666 / R 0.9896\n",
      "Tag: LOC - P 0.9177 / R 0.8357\n",
      "Tag: MISC - P 0.9039 / R 0.6822\n",
      "Tag: ORG - P 0.7721 / R 0.6381\n",
      "Tag: PER - P 0.8806 / R 0.8361\n",
      "Total time: 90.4874508381\n",
      "Epoch 10\n",
      "Training loss: 0.950928628445628445\n",
      "Training acc: 0.891411003777\n",
      "Validation loss: 0.965706467628\n",
      "\n",
      "[[42239    65    47   266   142]\n",
      " [  138  1797    17    90    52]\n",
      " [  312    39   860    37    20]\n",
      " [  473   106    28  1390    95]\n",
      " [  409    34     2    87  2617]]\n",
      "Tag: O - P 0.9694 / R 0.9878\n",
      "Tag: LOC - P 0.8805 / R 0.8582\n",
      "Tag: MISC - P 0.9015 / R 0.6782\n",
      "Tag: ORG - P 0.7433 / R 0.6644\n",
      "Tag: PER - P 0.8944 / R 0.8311\n",
      "Total time: 101.152304173\n",
      "Epoch 11\n",
      "Training loss: 0.950359344482344482\n",
      "Training acc: 0.89273208559\n",
      "Validation loss: 0.964469075203\n",
      "\n",
      "[[42307    51    60   217   124]\n",
      " [  155  1771    30    82    56]\n",
      " [  322    26   869    32    19]\n",
      " [  522    96    30  1353    91]\n",
      " [  441    21     7    57  2623]]\n",
      "Tag: O - P 0.9671 / R 0.9894\n",
      "Tag: LOC - P 0.9013 / R 0.8457\n",
      "Tag: MISC - P 0.8725 / R 0.6853\n",
      "Tag: ORG - P 0.7771 / R 0.6467\n",
      "Tag: PER - P 0.9004 / R 0.8330\n",
      "Total time: 97.6174690723\n",
      "Epoch 12\n",
      "Training loss: 0.950721979141979141\n",
      "Training acc: 0.89222133277\n",
      "Validation loss: 0.963994562626\n",
      "\n",
      "[[42247    48    51   257   156]\n",
      " [  139  1774    25    83    73]\n",
      " [  317    28   867    30    26]\n",
      " [  472    99    30  1380   111]\n",
      " [  375    19     1    72  2682]]\n",
      "Tag: O - P 0.9701 / R 0.9880\n",
      "Tag: LOC - P 0.9014 / R 0.8472\n",
      "Tag: MISC - P 0.8901 / R 0.6838\n",
      "Tag: ORG - P 0.7574 / R 0.6597\n",
      "Tag: PER - P 0.8799 / R 0.8517\n",
      "Total time: 104.005465984\n",
      "Epoch 13\n",
      "Training loss: 0.948978781778781758\n",
      "Training acc: 0.896425221367\n",
      "Validation loss: 0.96357357502\n",
      "\n",
      "[[42313    52    84   154   156]\n",
      " [  154  1779    28    76    57]\n",
      " [  302    25   893    28    20]\n",
      " [  537   101    40  1308   106]\n",
      " [  428    24     6    50  2641]]\n",
      "Tag: O - P 0.9675 / R 0.9896\n",
      "Tag: LOC - P 0.8980 / R 0.8496\n",
      "Tag: MISC - P 0.8497 / R 0.7043\n",
      "Tag: ORG - P 0.8094 / R 0.6252\n",
      "Tag: PER - P 0.8862 / R 0.8387\n",
      "Total time: 100.832801104\n",
      "Epoch 14\n",
      "Training loss: 0.948834478855478855\n",
      "Training acc: 0.896336821841\n",
      "Validation loss: 0.964374601841\n",
      "\n",
      "[[42263    92    52   208   144]\n",
      " [  140  1840    13    50    51]\n",
      " [  310    51   859    31    17]\n",
      " [  502   151    32  1312    95]\n",
      " [  420    41     5    55  2628]]\n",
      "Tag: O - P 0.9686 / R 0.9884\n",
      "Tag: LOC - P 0.8460 / R 0.8787\n",
      "Tag: MISC - P 0.8939 / R 0.6774\n",
      "Tag: ORG - P 0.7923 / R 0.6272\n",
      "Tag: PER - P 0.8954 / R 0.8346\n",
      "Total time: 105.708698034\n",
      "Epoch 15\n",
      "Training loss: 0.947654783726783726\n",
      "Training acc: 0.897815058368\n",
      "Validation loss: 0.962720751762\n",
      "\n",
      "[[42298    55    87   192   127]\n",
      " [  157  1787    32    68    50]\n",
      " [  303    28   889    30    18]\n",
      " [  514    97    34  1356    91]\n",
      " [  440    21     8    58  2622]]\n",
      "Tag: O - P 0.9677 / R 0.9892\n",
      "Tag: LOC - P 0.8989 / R 0.8534\n",
      "Tag: MISC - P 0.8467 / R 0.7011\n",
      "Tag: ORG - P 0.7958 / R 0.6482\n",
      "Tag: PER - P 0.9017 / R 0.8326\n",
      "Total time: 102.691318989\n",
      "Test\n",
      "=-=-=\n",
      "Writing predictions to q2_test.predicted\n"
     ]
    }
   ],
   "source": [
    "test_NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "1710 / 3181 : loss = 1.08583903313"
     ]
    }
   ],
   "source": [
    "test_NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
